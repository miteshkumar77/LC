{"id":407419221,"lang":"python","time":"1 year, 6 months","timestamp":1602437239,"status_display":"Accepted","runtime":"180 ms","url":"/submissions/detail/407419221/","is_pending":"Not Pending","title":"Web Crawler","memory":"21.6 MB","code":"# \"\"\"\n# This is HtmlParser's API interface.\n# You should not implement it, or speculate about its implementation\n# \"\"\"\n#class HtmlParser(object):\n#    def getUrls(self, url):\n#        \"\"\"\n#        :type url: str\n#        :rtype List[str]\n#        \"\"\"\n\nclass Solution(object):\n    def crawl(self, startUrl, htmlParser):\n        \"\"\"\n        :type startUrl: str\n        :type htmlParser: HtmlParser\n        :rtype: List[str]\n        \"\"\"\n        # https://example.org\n        def hostName(s):\n            tmp = s[7:]\n            i = tmp.find('/')\n            i = i if i != -1 else len(tmp)\n            tmp = tmp[:i]\n            return tmp\n        \n        \n        visited = set()\n        \n        from collections import deque\n        \n        q = deque()\n        host = hostName(startUrl)\n        \n        q.append(startUrl)\n        \n        while q:\n            top = q.popleft()\n            if top in visited or hostName(top) != host:\n                continue\n            visited.add(top)\n            l = htmlParser.getUrls(top)\n            for i in l:\n                q.append(i)\n        \n        return [i for i in visited]\n    \n            \n            \n            \n        \n        \n        \n        \n        \n        \n        ","compare_result":"11111111111111111111","title_slug":"web-crawler"}